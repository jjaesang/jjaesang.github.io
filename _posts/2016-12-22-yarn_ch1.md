---
layout: post
title:  "Apache Hadoop YARN 핵심 소개"
date: 2016-12-22 13:05:12
categories: YARN
author : Jaesang Lim
tag: YARN
cover: "/assets/hadoop_log.png"
---

### 아파치 하둡 YARN의 핵심 기능

- **YARN은 분산 애플리케이션을 구현하기 위한 범용적인 자원 관리 프레임워크** 
<center><img src="https://user-images.githubusercontent.com/12586821/47787348-07a34f00-dd52-11e8-9593-c0281914a071.png" height=200/></center>

- 문제 1 
 > - 하나의 Hadoop 클러스터는 다수의 서버로 구성되어 많은 컴퓨팅 리소스를 가지고 있는데 이 것을 하나의 컴퓨팅 플랫폼(MapReduce )에만 할당하는 것은 비효율적

- 문제 2 
 > - 여러 개의 컴퓨팅 플랫폼을 동시에 실행할 경우 각 서버의 리소스 ( 메모리 )가 부족하여 정상적으로 수행되던 작업들이 다른 작업에 의해 문제 발생 

- 기본적인 아이디어는 기존 JobTracker의 두 가지 중요한 부분의 책임을 분리하는 것
> - JobTracker를 ResourceManager와 ApplicationMaster로 분리
> - Non-MapReduce Workload의 호환
> - 확장성 향상 → 지원하는 노드 수(> 10k), 태스크 수(> 100k)
> - 클러스터 자원 이용률 개선 (> 70%)
> - 다양한 맵리듀스 프레임워크 버전 지원

<center>
<img src="https://user-images.githubusercontent.com/12586821/47787350-07a34f00-dd52-11e8-8179-4ef9a75667dc.PNG"/>
</center>

- ResourceManager
 > - 자원 스케줄링 ( Resource Scheduling ) 기능 ( = 클러스터 자원을 유일하게 중재 )

- ApplicationMaster
> - 맵리듀스 Job을 갖는 사용자 애플리케이션은 새로운 **ApplicationMaster** 컴포넌트를 통해 특정 자원을 요청

- Application Container
> - ApplicationMaster는 클러스터 내에 **Application Container** 생성하고 ResourceManager와 교섭

<hr/>



## 네임노드와 리소스매니저의 HA 구성에 대해 알아보자. 

### 1. 네임노드 HA

#### JournalNode
- editlog를 저장하고 공유하는 기능을 수행하는 서버 ( 자신의 로컬 디스크에 저장 ) 
- 네임노드는 JournalNode에 접근하기 위한 Client 역할
>  - ActiveNode :  editlog 저장 권한
>  - StandbyNode : editlog 조회 요청
- 물리적으로 분리된 3대의 서버에서 각각 실행 (  홀수 단위로 실행 ) 

#### ZKFC (ZooKeeperFailoverController)

- 주키퍼에 네임노드의 HA상태를 저장하려면 주키퍼를 제어하기 위한 주키퍼 Client 필요
- Active네임노드에 장애발생 시, Standby네임노드 전환
- 문제 발생한 네임노드를 HDFS에서 제외하는 역할
- 네임노드가 실행되고 있는 서버에서 별도의 데몬으로 실행
- 로컬 네임노드 상태 모니터링
- 주키퍼 세션 관리
- 자동 장애 처리 (failover) ActiveNN에 장애 발생시, ZKFC와 주키퍼 마스터 간의 세션은 종료 
- 이 때 스탠바이 네임노드의 ZKFC가 상태변화를 즉시 감지하고 액티브로 변환 

#### 네임노드 
 - 네임노드 내부에서 QJM(QuorumJournalManager) 이 JournalNode에 editlog 출력
 - 반절 이상의 JournalNode에서 정상 저장이 되면, 해당 editlog를 fsimage에 반영
 - 스탠바이 네임노드는 주기로 JournalNode에서 editlog 조회해, fsimage 갱신



#### FailOver처리 
1. Active NameNode는 edit log 처리용 epoch number를 할당 받는다
 > 이 번호는 uniq하게 증가하는 번호로 새로 할당 받은 번호는 이전 번호보다 항상 크다.

2. Active NameNode는 파일 시스템 변경 시 JournalNode로 변경 사항을 전송한다.
 > 전송 시 epoch number를 같이 전송한다.

3. JournalNode는 자신이 가지고 있는 epoch number 보다 큰 번호가 오면 자신의 번호를 새로운 번호로 갱신하고 해당 요청을 처리한다.

4. JournalNode는 자신이 가지고 있는 번호보다 작은 epoch number를 받으면 해당 요청은 처리하지 않는다.

5. Standby NameNode는 주기적(1분)으로 JournalNode로 부터 이전에 받은 edit log의 txid 이후의 정보를 받아 메모리의 파일 시스템 구조에 반영

6. Active NameNode 장애 발생 시 Standby NameNode는 마지막 받은 txid 이후의 모든 정보를 받아 메모리 구성에 반영 후 Active NameNode로 상태 변환


<hr/>

### 2. 리소스매니저(RM) HA

<img src="https://user-images.githubusercontent.com/12586821/47787351-07a34f00-dd52-11e8-98cb-d9610dd9e775.PNG" />
- 네임노드 HA는 ZKFC의 별도의 데몬 실행  
> - start-dfs.sh / stop-dfs.sh


- 리소스매지너의 HA는 내장되어 있음 ( EmbeddedElectorService 로 HA 상태 갱신 ) 
- 해당 호스트에 접근하여 yarn-daemon.sh 실행해야함
> - [Standby ResourceManager ] $ sbin/yarn-daemon.sh start resourcemanager


### YARN의 자원 모델 

- 이전의 하둡 버전
	- 클러스터의 각 노드는 실행할 수 있는 미리 정의된 맵 슬롯, 리듀스 슬롯을 정적으로 할당
	- 해당 슬롯은 맵과 리듀스 사이에서 공유될 수 없음
	- 맵리듀스 애플리케이션 라이프사이클 동안 다양하기 때문에 최적화되지 않음
	- 잡이 시작되면 맵 슬롯이 필요하고 잡의 종료시에는 리듀스 슬롯이 필요

- YARN
	- 많은 동적인 속성을 갖는 Container 형태로 요청받음
	- 메모리, CPU, 대역폭, GPU 지원 ( 각 자원모델의 최소.최댓값 지정가능 )



